# LLM-assisted OpenEvolve configuration for evolving Bloom filter alternatives.
max_iterations: 400
checkpoint_interval: 25

# LLM configuration
llm:
  primary_model: "gpt-4o"
  primary_model_weight: 0.85
  secondary_model: "gpt-4.1"
  secondary_model_weight: 0.15
  api_base: "https://api.openai.com/v1"
  temperature: 0.9  # Higher temperature for more creative exploration
  max_tokens: 12000
  timeout: 90

# Prompt configuration
prompt:
  system_message: >
    You are a creative data structures researcher exploring novel approaches to
    probabilistic set membership testing. Your goal is to discover NEW structures
    beyond traditional Bloom filters that minimize false positives while guaranteeing
    zero false negatives.

    CRITICAL CONSTRAINTS:
    - Only use Python standard library: hashlib, math
    - Available types: dict, list, set, bytearray, tuple, int, bytes
    - NO external libraries (no numpy, scipy, etc.)
    - You must IMPLEMENT structures from scratch
    - Don't reference undefined classes (e.g., don't use CuckooFilter unless you implement it)

    Explore diverse approaches (implement them yourself!):
    - Cuckoo filters: Store fingerprints with multiple hash positions
    - Quotient filters: Compact hash table with quotient/remainder
    - XOR filters: XOR-based fingerprint storage
    - Counting structures: Multiple hash functions for frequency tracking
    - Hybrid schemes: Mix of exact dict + approximate bit arrays
    - Hash table variations: Creative collision handling

    You can modify the entire Candidate class:
    - Change __init__ to initialize different structures
    - Add helper methods (_hash, _displace, _compress, etc.)
    - Create helper classes inside EVOLVE-BLOCK (class Bucket, class Filter, etc.)

    Optimize for: low false positive rate, fast queries, reasonable memory usage.

# Database configuration
database:
  population_size: 128
  archive_size: 48
  num_islands: 4
  elite_selection_ratio: 0.20  # Keep fewer elites to make room for novelty
  exploitation_ratio: 0.45      # Lower exploitation, higher exploration
  embedding_model: "text-embedding-3-small"
  similarity_threshold: 0.92    # Lower threshold to keep more diverse candidates

# Evaluator coordination
evaluator:
  timeout: 75
  cascade_evaluation: false
  parallel_evaluations: 2  # Start with 2 workers, can increase to 4

# Evolution settings
diff_based_evolution: true
max_code_length: 18000

# OpenEvolve problem wiring
problem:
  id: bloom-filter-alternative
  description: >
    Search for probabilistic set-membership data structures that outperform a
    standard Bloom filter baseline under realistic read-heavy workloads.
  evaluator:
    python_module: randomize_evolve.evaluators.bloom_alternatives
    callable: Evaluator
    kwargs:
      config:
        key_bits: 32
        positives: 5000
        queries: 10000
        negative_fraction: 0.5
        seeds: [17, 23, 71, 89, 131]
        build_timeout_s: 1.0
        query_timeout_s: 1.0
        false_negative_penalty: 1000000.0
        false_positive_weight: 180.0
        memory_weight: 0.05
        latency_weight: 8.0
        max_memory_bytes: 104857600

search:
  population_size: 128
  max_generations: 400
  survivor_fraction: 0.25
  seed: 123456
  notes: >
    Adjust representation and operators as needed; the evaluator expects a
    factory callable returning an object with add() and query() methods matching
    the BloomAlternativeEvaluator protocol.
